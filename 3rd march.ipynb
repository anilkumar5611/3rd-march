{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "787e79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Explain the concept of precision and recall in the context of classification models.\n",
    "\n",
    "# Answer: Precision measures the proportion of true positive predictions among all positive predictions made by the model. \n",
    "#     Recall measures the proportion of true positive predictions among all actual positive instances in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4fc75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: What is the F1 score and how is it calculated? How is it different from precision and recall?\n",
    "\n",
    "# Answer: The F1 score is the harmonic mean of precision and recall, calculated as 2 * (precision * recall) / (precision + recall)\n",
    "#     . It balances precision and recall into a single metric, providing a more comprehensive measure of a model's performance \n",
    "#     compared to precision and recall alone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bdabd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: What is ROC and AUC, and how are they used to evaluate the performance of classification models?\n",
    "\n",
    "# Answer: ROC (Receiver Operating Characteristic) is a graphical plot that illustrates the trade-off between the true positive \n",
    "#     rate (TPR) and the false positive rate (FPR) at various threshold settings. AUC (Area Under the Curve) measures the area \n",
    "#     under the ROC curve, with higher AUC indicating better model performance. They are used to assess the discriminative \n",
    "#     ability of a classification model across different threshold values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e55247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4: How do you choose the best metric to evaluate the performance of a classification model?\n",
    "\n",
    "# Answer: The choice of evaluation metric depends on the specific objectives and requirements of the problem. For example, if\n",
    "#     minimizing false positives is critical, precision may be the preferred metric. If capturing as many true positives as\n",
    "#     possible is essential, recall may be prioritized. F1 score provides a balanced evaluation, while ROC AUC assesses overall \n",
    "#     classification performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ef1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: What is multiclass classification and how is it different from binary classification?\n",
    "\n",
    "# Answer: Multiclass classification involves predicting the target variable with more than two classes, whereas binary \n",
    "#     classification deals with only two classes. In multiclass classification, the model needs to distinguish between \n",
    "#     multiple classes, while binary classification focuses on distinguishing between just two classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326cadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6: Explain how logistic regression can be used for multiclass classification.\n",
    "\n",
    "# Answer: Logistic regression can be extended to handle multiclass classification using techniques like one-vs-rest (OvR) or \n",
    "#     one-vs-one (OvO) approaches. In OvR, separate logistic regression models are trained for each class, treating it as the \n",
    "#     positive class and the rest as the negative class. In OvO, pairwise logistic regression models are trained for each pair \n",
    "#     of classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b68239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
